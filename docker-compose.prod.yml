version: '3.9'

services:
  # PostgreSQL - Primary Database
  postgres:
    image: postgres:16-alpine
    container_name: nexuscomm_postgres_prod
    environment:
      POSTGRES_USER: nexuscomm_prod
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: nexuscomm_prod
      POSTGRES_INITDB_ARGS: "-c max_connections=200 -c shared_buffers=256MB"
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nexuscomm_prod -d nexuscomm_prod"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - nexuscomm_net
    restart: always

  # Redis - Caching & Pub/Sub
  redis:
    image: redis:7-alpine
    container_name: nexuscomm_redis_prod
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data_prod:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - nexuscomm_net
    restart: always

  # Elasticsearch - Full-Text Search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    container_name: nexuscomm_elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - nexuscomm_net
    restart: always

  # Kibana - Elasticsearch UI (Optional for monitoring)
  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.0
    container_name: nexuscomm_kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - nexuscomm_net
    restart: always

  # RabbitMQ - Message Broker (Optional, for advanced scenarios)
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: nexuscomm_rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - nexuscomm_net
    restart: always

  # Kafka - Event Streaming (Optional, for Kafka-based messaging)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: nexuscomm_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    networks:
      - nexuscomm_net
    restart: always

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: nexuscomm_kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "9092:9092"
    networks:
      - nexuscomm_net
    restart: always

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: nexuscomm_backend_prod
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    environment:
      NODE_ENV: production
      PORT: 3000
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: nexuscomm_prod
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: nexuscomm_prod
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka:9092
      JWT_SECRET: ${JWT_SECRET}
      ENCRYPTION_SECRET: ${ENCRYPTION_SECRET}
      CLIENT_URL: ${CLIENT_URL}
      API_URL: http://backend:3000
    ports:
      - "3000:3000"
    networks:
      - nexuscomm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always

  # Frontend Web App (Next.js)
  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: nexuscomm_web_prod
    depends_on:
      - backend
    environment:
      NEXT_PUBLIC_API_URL: http://backend:3000/api
      NODE_ENV: production
    ports:
      - "3001:3001"
    networks:
      - nexuscomm_net
    restart: always

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: nexuscomm_prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    networks:
      - nexuscomm_net
    restart: always

  # Grafana - Visualization
  grafana:
    image: grafana/grafana:latest
    container_name: nexuscomm_grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "3002:3000"
    depends_on:
      - prometheus
    networks:
      - nexuscomm_net
    restart: always

  # ELK Stack - Logging (Logstash)
  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.0
    container_name: nexuscomm_logstash
    volumes:
      - ./monitoring/logstash/config:/usr/share/logstash/config
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline
    environment:
      - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
    ports:
      - "5000:5000"
    depends_on:
      - elasticsearch
    networks:
      - nexuscomm_net
    restart: always

  # Nginx - Reverse Proxy & Load Balancer
  nginx:
    image: nginx:alpine
    container_name: nexuscomm_nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
      - web
    networks:
      - nexuscomm_net
    restart: always

volumes:
  postgres_data_prod:
  redis_data_prod:
  elasticsearch_data:
  rabbitmq_data:
  zookeeper_data:
  kafka_data:
  prometheus_data:
  grafana_data:

networks:
  nexuscomm_net:
    driver: bridge
